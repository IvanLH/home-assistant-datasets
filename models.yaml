---
# This is the model configuration file used by the `home-assistant-datasets`
# tool. Each entry is a ConfigEntry that configures a specific model type
# with whatever integration is needed (either core integration or custom component).
#
# Some models require secrets such as API keys or urls that are specific to you
# and not checked into the repository and referenced in this file like `!secret openai_api_key`.
# Create a file called `secrets.yaml` and include the necessary keys.
models:
  - model_id: assistant
    domain: homeassistant
    description: The Home Assisatnt NLP assistant pipeline

  - model_id: gpt-3.5
    domain: openai_conversation
    description: Open AI Conversation integration using gpt-3.5
    url:
      - https://platform.openai.com/docs/models/gpt-3-5-turbo
    config_entry_data:
      api_key: !secret openai_api_key
    config_entry_options:
      chat_model: gpt-3.5-turbo-1106
      llm_hass_api: assist

  - model_id: gpt-4o
    domain: openai_conversation
    description: Open AI Conversation integration using gpt-4o
    url:
      - https://platform.openai.com/docs/models/gpt-4o
    config_entry_data:
      api_key: !secret openai_api_key
    config_entry_options:
      chat_model: gpt-4o
      llm_hass_api: assist

  - model_id: gpt-4o-mini
    domain: openai_conversation
    description: Open AI Conversation integration using gpt-4o-mini
    url:
      - https://platform.openai.com/docs/models/gpt-4o-mini
    config_entry_data:
      api_key: !secret openai_api_key
    config_entry_options:
      chat_model: gpt-4o-mini
      llm_hass_api: assist

  - model_id: gemini-pro
    domain: google_generative_ai_conversation
    description: Google Generative AI integration using gemini pro (v1)
    url:
      - https://deepmind.google/technologies/gemini/pro/
    config_entry_data:
      api_key: !secret google_api_key
    config_entry_options:
      chat_model: models/gemini-pro
      llm_hass_api: assist

  - model_id: gemini-1.5-flash
    domain: google_generative_ai_conversation
    description: Google Generative AI integration using gemini flash (v1.5)
    url:
      - https://blog.google/products/gemini/google-gemini-new-features-july-2024/
    config_entry_data:
      api_key: !secret google_api_key
    config_entry_options:
      chat_model: models/gemini-1.5-flash-latest
      llm_hass_api: assist

  # Using an openai compatible custom component
  # https://github.com/allenporter/hass-openai-custom-conversation
  - model_id: functionary-small-v2.5
    description: A custom open AI integration using functionary small v2.5 with a modified pre-release llama cpp python server.
    domain: vicuna_conversation
    urL:
      - https://huggingface.co/meetkai/functionary-small-v2.5
      - https://github.com/abetlen/llama-cpp-python
      - https://github.com/allenporter/functionary-server
    config_entry_data:
      api_key: sk-0000000000000000000
      # Update with your openai compatible functionary url
      base_url: http://functionary.functionary:8000/v1
    config_entry_options:
      chat_model: functionary-small-v2.5
      llm_hass_api: assist

  - model_id: mistral-v3
    domain: ollama
    description: Mistral V3 using Ollama
    url:
    - https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3
    - https://ollama.com/library/mistral
    - https://mistral.ai/news/announcing-mistral-7b/
    config_entry_data:
      url: !secret ollama_url
      model: mistral:latest
    config_entry_options:
      llm_hass_api: assist

  - model_id: llama3
    domain: ollama
    description: Llama 3 from Meta using Ollama
    url:
    - https://ollama.com/library/llama3
    config_entry_data:
      url: !secret ollama_url
      model: llama3:latest

  - model_id: llama3.1
    domain: ollama
    description: Llama 3.1 from Meta using Ollama
    url:
    - https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct
    - https://ollama.com/library/llama3.1
    config_entry_data:
      url: !secret ollama_url
      model: llama3.1:latest
    config_entry_options:
      llm_hass_api: assist

  - model_id: xlam-1b
    domain: ollama
    description: XLam 1B model from Salesforce using Ollama
    url:
    - https://huggingface.co/Salesforce/xLAM-1b-fc-r
    - https://github.com/SalesforceAIResearch/xLAM
    - https://ollama.com/allenporter/xlam:1b
    config_entry_data:
      url: !secret ollama_url
      model: allenporter/xlam:1b
    config_entry_options:
      llm_hass_api: assist

  - model_id: xlam-7b
    domain: ollama
    description: XLam 7B model from Salesforce using Ollama
    url:
    - https://huggingface.co/Salesforce/xLAM-7b-fc-r
    - https://github.com/SalesforceAIResearch/xLAM
    - https://ollama.com/allenporter/xlam:7b
    config_entry_data:
      url: !secret ollama_url
      model: allenporter/xlam:7b
    config_entry_options:
      llm_hass_api: assist

  - model_id: gemma
    domain: ollama
    description: Gemma from Google using Ollama
    url:
    - https://ollama.com/library/gemma
    - https://ai.google.dev/gemma/docs/model_card
    config_entry_data:
      url: !secret ollama_url
      model: gemma:7b

  - model_id: llama3-groq-tool-use
    domain: ollama
    description: Groq tool use model fine tuned from llama3using Ollama
    url:
    - https://ollama.com/library/llama3-groq-tool-use
    - https://console.groq.com/docs/tool-use
    config_entry_data:
      url: !secret ollama_url
      model: llama3-groq-tool-use:latest
    config_entry_options:
      llm_hass_api: assist

  # Configuration for home-llm custom component https://github.com/acon96/home-llm
  - model_id: home-llm
    domain: llama_conversation
    description: The home-llm 3B v3 model and custom component using service calls to control Home Assistant.
    url:
    - https://github.com/acon96/home-llm/
    - https://huggingface.co/acon96/Home-3B-v3-GGUF
    - https://ollama.com/fixt/home-3b-v3
    version: 2
    # Home LLM has a very complex configuration that depends on the specific backend
    # and model used. You're on your own to figure out the valid values to enter here.
    config_entry_data:
      model_backend: ollama
      host: ollama.ollama
      port: "11434"
      ssl: false
      huggingface_model: fixt/home-3b-v3:latest
    config_entry_options:
      llm_hass_api: home-llm-service-api
      prompt: "You are 'Al', a helpful AI Assistant that controls the devices in a house. Complete the following task as instructed with the information provided only.\nThe current time and date is {{ (as_timestamp(now()) | timestamp_custom(\"%I:%M %p on %A %B %d, %Y\", \"\")) }}\nServices: {{ formatted_tools }}\nDevices:\n{{ formatted_devices }}"
      prompt_template: "zephyr"
      tool_format: "min_tool_format"
      tool_multi_turn_chat: false
      in_context_examples: false
      in_context_examples_file: "in_context_examples.csv"
      num_in_context_examples: 4.0
      max_new_tokens: 128
      context_length: 2048.0
      top_k: 40.0
      temperature: 0.1
      top_p: 1.0
      typical_p: 1.0
      ollama_json_mode: false
      request_timeout: 90.0
      ollama_keep_alive: 30.0
      remote_use_chat_endpoint: false
      extra_attributes_to_expose:
        - rgb_color
        - brightness
        - temperature
        - humidity
        - fan_mode
        - media_title
        - volume_level
        - item
        - wind_speed
      service_call_regex: "```homeassistant\\n([\\S \\t\\n]*?)```"
      refresh_prompt_per_turn: true
      remember_conversation: true
      remember_num_interactions: 5
